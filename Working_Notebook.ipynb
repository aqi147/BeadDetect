{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPp8ff9gvBr6cd1B3llIMF4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aqi147/BeadDetect/blob/main/Working_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use this google colab link to download the model\n",
        "\n"
      ],
      "metadata": {
        "id": "qzbsQdIBe0r2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "498a1136-78d8-495f-9bc5-dde5625b1d79",
        "id": "YIDHzGidezsz"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1FryT6bsIu_9Ez1L_BwhybTNQTY__qm9N\n",
            "From (redirected): https://drive.google.com/uc?id=1FryT6bsIu_9Ez1L_BwhybTNQTY__qm9N&confirm=t&uuid=7f6e7d6c-62a6-468e-83f6-8aef67d43070\n",
            "To: /content/BD_model.pt\n",
            "100% 94.7M/94.7M [00:03<00:00, 25.3MB/s]\n",
            "BD_model.pt  sample_data\n"
          ]
        }
      ],
      "source": [
        "!pip install -q gdown\n",
        "!gdown --fuzzy \"https://drive.google.com/file/d/1FryT6bsIu_9Ez1L_BwhybTNQTY__qm9N/view?usp=sharing\" -O BD_model.pt\n",
        "\n",
        "\n",
        "\n",
        "!ls   # Check if the File is Downloaded\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clone YOLOv5 and Set Up the Environment"
      ],
      "metadata": {
        "id": "S2qN0OXuPR8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the YOLOv5 repository\n",
        "!git clone https://github.com/ultralytics/yolov5  # Clone the YOLOv5 repo\n",
        "%cd yolov5\n",
        "\n",
        "# Install YOLOv5 dependencies\n",
        "%pip install -qr requirements.txt  # Install required packages\n",
        "%pip install -q roboflow  # Install Roboflow for data management (if needed)\n",
        "\n",
        "# Import required libraries\n",
        "import torch\n",
        "import os\n",
        "from IPython.display import Image, clear_output  # To display images\n",
        "\n",
        "# Verify setup\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")\n"
      ],
      "metadata": {
        "id": "c4pc-ofBPVtf",
        "outputId": "40e3f463-c72a-449b-bde3-6cc1f2986dba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 17265, done.\u001b[K\n",
            "remote: Total 17265 (delta 0), reused 0 (delta 0), pack-reused 17265 (from 1)\u001b[K\n",
            "Receiving objects: 100% (17265/17265), 16.11 MiB | 16.08 MiB/s, done.\n",
            "Resolving deltas: 100% (11858/11858), done.\n",
            "/content/yolov5\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m913.6/913.6 kB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m81.5/81.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hSetup complete. Using torch 2.5.1+cu121 (Tesla T4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Object Detection Using YOLOv5"
      ],
      "metadata": {
        "id": "_MX9BlhMPU9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run YOLOv5 object detection\n",
        "# Generalize the model and image source paths\n",
        "model_path = \"/content/BD_model.pt\"  # Replace with the path to your trained YOLOv5 model (e.g., 'BD_model.pt')\n",
        "image_source = \"<path to images>\"  # Replace with the path to the folder or file containing images/videos\n",
        "\n",
        "\n",
        "# Command for object detection\n",
        "!python detect.py --weights {model_path} --img 1280 --conf 0.4 --source {image_source} --save-txt  --hide-labels    # it will save the results in the runs/detect/exp/ directory. img 3328\n",
        "\n",
        "# Explanation:\n",
        "# --weights: Path to the trained YOLOv5 model file.\n",
        "# --img: Image size for processing (e.g., 640, 1280,2560, etc. pixels).\n",
        "# --conf: Confidence threshold for predictions (you can adjust).\n",
        "# --source: Path to the image or video source.\n",
        "# --save-txt: Save the detection results in text format.\n",
        "# --hide-conf: Hide confidence scores in the output images.\n"
      ],
      "metadata": {
        "id": "h3xwutDpPhJ3",
        "outputId": "30d7bb70-2039-4880-c832-8cefdc6ab165",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/BD_model.pt'], source=/content/drive/MyDrive/Example_images, data=data/coco128.yaml, imgsz=[1280, 1280], conf_thres=0.4, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_format=0, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=True, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 üöÄ v7.0-397-gde62f93c Python-3.11.11 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 267 layers, 46108278 parameters, 0 gradients, 107.6 GFLOPs\n",
            "WARNING ‚ö†Ô∏è NMS time limit 0.550s exceeded\n",
            "image 1/18 /content/drive/MyDrive/Example_images/F1.jpg: 352x1280 18 os, 56.9ms\n",
            "image 2/18 /content/drive/MyDrive/Example_images/R003849001_1.jpg: 352x1280 42 os, 28.9ms\n",
            "image 3/18 /content/drive/MyDrive/Example_images/R003849007_33.jpg: 352x1280 46 os, 28.9ms\n",
            "image 4/18 /content/drive/MyDrive/Example_images/R003849018_99.jpg: 320x1280 49 os, 35.6ms\n",
            "image 5/18 /content/drive/MyDrive/Example_images/R003851056_1221.jpg: 352x1280 64 os, 28.7ms\n",
            "image 6/18 /content/drive/MyDrive/Example_images/R003852137_2411.jpg: 352x1280 17 os, 31.0ms\n",
            "image 7/18 /content/drive/MyDrive/Example_images/R003852140_2419.jpg: 320x1280 27 os, 27.4ms\n",
            "image 8/18 /content/drive/MyDrive/Example_images/b1_niva.JPG: 1280x1280 282 os, 99.0ms\n",
            "image 9/18 /content/drive/MyDrive/Example_images/b2_niva.JPG: 1152x1280 361 os, 86.7ms\n",
            "image 10/18 /content/drive/MyDrive/Example_images/f2.JPG: 928x1280 59 os, 69.1ms\n",
            "image 11/18 /content/drive/MyDrive/Example_images/f3_NIVA.jpg: 1280x1216 55 os, 95.2ms\n",
            "image 12/18 /content/drive/MyDrive/Example_images/f4_niva.JPG: 672x1280 30 os, 51.7ms\n",
            "image 13/18 /content/drive/MyDrive/Example_images/f5_niva.JPG: 800x1280 78 os, 62.9ms\n",
            "image 14/18 /content/drive/MyDrive/Example_images/f6_niva.JPG: 800x1280 57 os, 59.8ms\n",
            "image 15/18 /content/drive/MyDrive/Example_images/f7_niva.JPG: 992x1280 60 os, 73.9ms\n",
            "image 16/18 /content/drive/MyDrive/Example_images/v1.jpg: 1216x1280 116 os, 92.3ms\n",
            "image 17/18 /content/drive/MyDrive/Example_images/v2.jpg: 928x1280 204 os, 67.9ms\n",
            "image 18/18 /content/drive/MyDrive/Example_images/v3.jpg: 704x1280 56 os, 51.2ms\n",
            "Speed: 0.9ms pre-process, 58.2ms inference, 35.1ms NMS per image at shape (1, 3, 1280, 1280)\n",
            "Results saved to \u001b[1mruns/detect/exp28\u001b[0m\n",
            "18 labels saved to runs/detect/exp28/labels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summarize the Detection Results"
      ],
      "metadata": {
        "id": "VWV-A3DTQLdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the directory containing label files\n",
        "dir = \"runs/detect/exp/labels\"  # Path to the folder with detection result labels\n",
        "\n",
        "# Open a file to save the summary\n",
        "summary_file = os.path.dirname(dir) + \"/summary.txt\"\n",
        "with open(summary_file, \"w\") as summary:\n",
        "    # Iterate through all label files in the directory\n",
        "    for file in os.listdir(dir):\n",
        "        # Count the number of lines (detections) in each label file\n",
        "        num_lines = sum(1 for _ in open(dir + \"/\" + file))\n",
        "        # Write the file name and number of detections to the summary\n",
        "        summary.write(file + \"\\t\" + str(num_lines) + \"\\n\")\n",
        "\n",
        "# Summary saved to the specified file\n",
        "print(f\"Summary of detections saved to: {summary_file}\")\n"
      ],
      "metadata": {
        "id": "e4_0xHzbQLut"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}